spring.application.name=spring-ai-poc

spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3
#spring.ai.ollama.init.pull-model-strategy=always

# Context size must be big enough to hold the entire document + prompt
spring.ai.ollama.chat.options.num-ctx=4096

# Request timeout must be long enough for LLM to produce a response
spring.mvc.async.request-timeout=600000

# Max file size must be big enough to fit the document
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
spring.servlet.multipart.resolve-lazily=true